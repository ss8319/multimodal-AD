"""
Evaluate sMRI-only baseline using a pre-trained BrainIAC backbone + trained linear probe
on the SAME cross-validation splits as fusion/protein baselines.

This script performs INFERENCE ONLY per fold (no training):
1) Maintain BrainIAC validation preprocessing
2) Read CV splits generated by fusion (expects 'test' indices per fold)
3) Load pre-trained backbone and trained linear probe checkpoint (.ckpt)
4) Run images -> model -> logits (sigmoid) on the test set for each fold
5) Compute the same metrics as protein baseline (Accuracy, Balanced Acc, AUC, Precision, Recall, F1, MCC)
6) Aggregate metrics across folds and save optional JSON
"""

import argparse
import json
from pathlib import Path
from typing import List, Tuple

import numpy as np
import pandas as pd

import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

from sklearn.metrics import (
    accuracy_score,
    balanced_accuracy_score,
    confusion_matrix,
    precision_recall_fscore_support,
    roc_auc_score,
    matthews_corrcoef,
)

# Add BrainIAC src to path for model + transforms
import sys

# Calculate absolute path to BrainIAC src directory
_brainiac_src = Path(__file__).resolve().parents[3] / 'src' / 'mri' / 'BrainIAC' / 'src'
_brainiac_src_str = str(_brainiac_src)
if _brainiac_src_str not in sys.path:
    sys.path.insert(0, _brainiac_src_str)

# Now import BrainIAC modules
from model import ViTBackboneNet, Classifier, SingleScanModel  # type: ignore
from dataset import get_validation_transform  # type: ignore


def normalize_path(path_str: str) -> Path:
    """Normalize to absolute path, stripping duplicate project prefix if present."""
    if isinstance(path_str, str) and path_str.startswith('multimodal-AD/'):
        cwd = Path.cwd()
        if cwd.name == 'multimodal-AD' or str(cwd).endswith('/multimodal-AD'):
            path_str = path_str.replace('multimodal-AD/', '', 1)
    return Path(path_str).expanduser().resolve()


class MRIDatasetFromPaths(Dataset):
    """Minimal dataset wrapping MRI file paths and labels using BrainIAC validation transform."""

    def __init__(self, image_paths: List[Path], labels: np.ndarray, image_size: Tuple[int, int, int] = (96, 96, 96)):
        self.image_paths = image_paths
        self.labels = labels.astype(int)
        self.transform = get_validation_transform(image_size=image_size)

    def __len__(self) -> int:
        return len(self.image_paths)

    def __getitem__(self, idx: int):
        path = str(self.image_paths[idx])
        sample = {"image": path}
        sample = self.transform(sample)
        image = sample["image"]  # [1, D, H, W]
        label = int(self.labels[idx])
        return {"image": image, "label": torch.tensor(label, dtype=torch.long)}


def load_brainiac_linear_probe(checkpoint_path: Path, simclr_ckpt_path: Path, device: torch.device) -> torch.nn.Module:
    """Recreate BrainIAC backbone + linear probe and load weights from Lightning .ckpt."""
    """Code copied with light modification from BrainIAC/src/test_inference_finetune.py"""
    backbone = ViTBackboneNet(simclr_ckpt_path=str(simclr_ckpt_path))
    classifier = Classifier(d_model=768, num_classes=1)  # Binary classification
    model = SingleScanModel(backbone, classifier)

    checkpoint = torch.load(str(checkpoint_path), map_location='cpu', weights_only=False)
    # Extract state dict - handle Lightning module format
    if "state_dict" in checkpoint:
        state_dict = checkpoint["state_dict"]
        # Remove Lightning module prefixes
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith("model."):
                new_key = key[6:]  # Remove "model." prefix
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value
        state_dict = new_state_dict
    else:
        state_dict = checkpoint

    model.load_state_dict(state_dict, strict=True)
    model.eval()
    model.to(device)
    return model


def _safe_auc_score(y_true: np.ndarray, y_prob: np.ndarray) -> float:
    """Return AUC with robust handling for degenerate cases."""
    unique_labels = np.unique(y_true)
    unique_preds = np.unique((y_prob >= 0.5).astype(int))
    if len(unique_labels) < 2:
        return float('nan')
    if len(unique_preds) < 2:
        return 0.5
    try:
        return float(roc_auc_score(y_true, y_prob))
    except ValueError:
        return float('nan')


def evaluate_fold(model: torch.nn.Module, device: torch.device, df: pd.DataFrame, test_indices: np.ndarray,
                  image_size: Tuple[int, int, int] = (96, 96, 96)) -> dict:
    """Run inference for a single fold's test set and compute metrics."""
    # Prepare data
    y_all = (df['research_group'] == 'AD').astype(int).values
    mri_paths = df['mri_path'].tolist()

    fold_paths = [normalize_path(mri_paths[i]) for i in test_indices]
    fold_labels = y_all[test_indices]

    dataset = MRIDatasetFromPaths(fold_paths, fold_labels, image_size=image_size)
    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)

    all_probs: List[float] = []
    all_preds: List[int] = []
    all_labels: List[int] = []

    with torch.no_grad():
        for batch in dataloader:
            images = batch['image'].to(device)
            labels = batch['label'].to(device)
            logits = model(images)
            probs = torch.sigmoid(logits).squeeze(1)  # [B]
            preds = (probs > 0.5).long()

            all_probs.extend(probs.cpu().numpy().tolist())
            all_preds.extend(preds.cpu().numpy().tolist())
            all_labels.extend(labels.cpu().numpy().tolist())

    y_true = np.asarray(all_labels, dtype=int)
    y_pred = np.asarray(all_preds, dtype=int)
    y_prob = np.asarray(all_probs, dtype=float)

    # Metrics
    test_acc = float(accuracy_score(y_true, y_pred))
    test_balanced_acc = float(balanced_accuracy_score(y_true, y_pred))
    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary', zero_division=0)
    test_auc = _safe_auc_score(y_true, y_prob)
    test_cm = confusion_matrix(y_true, y_pred, labels=[0, 1])
    test_mcc = float(matthews_corrcoef(y_true, y_pred))

    return {
        'test_acc': test_acc,
        'test_balanced_acc': test_balanced_acc,
        'test_auc': test_auc,
        'test_precision': float(precision),
        'test_recall': float(recall),
        'test_f1': float(f1),
        'test_mcc': test_mcc,
        'test_cm': test_cm.tolist(),
        'n_test': int(len(y_true)),
    }


def print_fold_results(results: dict, fold_idx: int) -> None:
    print(f"\nFold {fold_idx} Test Results:")
    print(f"  Accuracy: {results['test_acc']:.4f}")
    print(f"  Balanced Accuracy: {results['test_balanced_acc']:.4f}")
    if np.isnan(results['test_auc']):
        print("  AUC: undefined")
    else:
        print(f"  AUC: {results['test_auc']:.4f}")
    print(f"  Precision: {results['test_precision']:.4f}")
    print(f"  Recall: {results['test_recall']:.4f}")
    print(f"  F1: {results['test_f1']:.4f}")
    print(f"  MCC: {results['test_mcc']:.4f}")
    cm = np.array(results['test_cm'])
    print("  Confusion Matrix:")
    print(f"    TN={cm[0,0]}, FP={cm[0,1]}")
    print(f"    FN={cm[1,0]}, TP={cm[1,1]}")


def aggregate_results(fold_results: List[dict]) -> Tuple[dict, np.ndarray]:
    metrics = ['test_acc', 'test_balanced_acc', 'test_auc', 'test_precision', 'test_recall', 'test_f1', 'test_mcc']
    aggregated = {}

    print("\n" + "="*60)
    print("CROSS-VALIDATION RESULTS SUMMARY (sMRI-ONLY BASELINE)")
    print("="*60)

    for metric in metrics:
        values = [fr[metric] for fr in fold_results]
        if metric == 'test_auc' and any(np.isnan(v) for v in values):
            aggregated[metric] = {
                'mean': float('nan'),
                'std': float('nan'),
                'values': values,
            }
            name = metric.replace('test_', '').replace('_', ' ').upper()
            print(f"{name}: undefined (some folds had undefined AUC)")
        else:
            valid = [v for v in values if not (isinstance(v, float) and np.isnan(v))]
            if valid:
                aggregated[metric] = {
                    'mean': float(np.mean(valid)),
                    'std': float(np.std(valid)),
                    'values': values,
                }
                name = metric.replace('test_', '').replace('_', ' ').upper()
                print(f"{name}: {aggregated[metric]['mean']:.4f} ± {aggregated[metric]['std']:.4f}")
            else:
                aggregated[metric] = {
                    'mean': float('nan'),
                    'std': float('nan'),
                    'values': values,
                }
                name = metric.replace('test_', '').replace('_', ' ').upper()
                print(f"{name}: undefined (all folds had undefined values)")

    total_cm = np.sum([np.array(fr['test_cm']) for fr in fold_results], axis=0)
    print("\nAggregated Confusion Matrix:")
    print(f"  TN={total_cm[0,0]}, FP={total_cm[0,1]}")
    print(f"  FN={total_cm[1,0]}, TP={total_cm[1,1]}")

    return aggregated, total_cm


def main():
    parser = argparse.ArgumentParser(
        description="Evaluate BrainIAC linear-probe sMRI model on fusion CV splits (inference only)"
    )
    parser.add_argument('--data-csv', type=str, required=True,
                        help='CSV containing paired dataset with column mri_path and research_group')
    parser.add_argument('--cv-splits-json', type=str, required=True,
                        help='cv_splits.json produced by fusion run (expects list of {test: [...]})')
    parser.add_argument('--checkpoint-path', type=str, required=True,
                        help='Path to BrainIAC linear probe checkpoint (.ckpt)')
    parser.add_argument('--simclr-ckpt-path', type=str, required=True,
                        help='Path to BrainIAC SimCLR backbone checkpoint (.ckpt)')
    parser.add_argument('--save-dir', type=str, default=None,
                        help='Directory to save results JSON')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                        choices=['cpu', 'cuda'])
    parser.add_argument('--image-size', type=int, nargs=3, default=[96, 96, 96],
                        help='Validation crop size used by BrainIAC models')
    args = parser.parse_args()

    data_csv = normalize_path(args.data_csv)
    cv_splits_json = normalize_path(args.cv_splits_json)
    checkpoint_path = normalize_path(args.checkpoint_path)
    simclr_ckpt_path = normalize_path(args.simclr_ckpt_path)
    save_dir = normalize_path(args.save_dir) if args.save_dir else None

    device = torch.device(args.device)
    image_size = tuple(int(x) for x in args.image_size)

    print("="*60)
    print("sMRI-ONLY BASELINE EVALUATION (BrainIAC linear probe)")
    print("="*60)
    print(f"Data CSV: {data_csv}")
    print(f"CV Splits: {cv_splits_json}")
    print(f"Checkpoint: {checkpoint_path}")
    print(f"SimCLR Backbone: {simclr_ckpt_path}")
    print(f"Device: {device}")
    print()

    # Load data and splits
    df = pd.read_csv(str(data_csv))
    with open(str(cv_splits_json), 'r') as f:
        cv_splits = json.load(f)

    # Load model (frozen, inference only)
    model = load_brainiac_linear_probe(checkpoint_path, simclr_ckpt_path, device)

    fold_results = []
    for fold_idx, split in enumerate(cv_splits, start=1):
        # Expect protein/fusion-style splits with 'test' indices
        if 'test' not in split:
            raise KeyError("CV split must contain 'test' key with indices to evaluate")
        test_idx = np.asarray(split['test'], dtype=int)

        print("-"*60)
        print(f"FOLD {fold_idx}/{len(cv_splits)}  |  Test size: {len(test_idx)}")

        res = evaluate_fold(
            model=model,
            device=device,
            df=df,
            test_indices=test_idx,
            image_size=image_size,
        )
        res['fold'] = fold_idx
        fold_results.append(res)
        print_fold_results(res, fold_idx)

    aggregated, total_cm = aggregate_results(fold_results)

    if save_dir is not None:
        save_dir.mkdir(parents=True, exist_ok=True)
        output = {
            'fold_results': fold_results,
            'aggregated_metrics': {
                k: {
                    'mean': None if isinstance(v['mean'], float) and np.isnan(v['mean']) else v['mean'],
                    'std': None if isinstance(v['std'], float) and np.isnan(v['std']) else v['std'],
                    'values': [None if isinstance(x, float) and np.isnan(x) else x for x in v['values']],
                } for k, v in aggregated.items()
            },
            'aggregated_cm': total_cm.tolist(),
        }
        with open(save_dir / 'mri_linear_probe_baseline_results.json', 'w') as f:
            json.dump(output, f, indent=2)
        print(f"\n✅ Results saved to: {save_dir / 'mri_linear_probe_baseline_results.json'}")


if __name__ == '__main__':
    main()


