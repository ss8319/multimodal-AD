"""
Evaluate sMRI-only baseline using DINOv3 backbone + sklearn logistic regression
on the SAME cross-validation splits as fusion/protein baselines.

This script performs INFERENCE ONLY per fold (no training):
1) Use DINOv3's slice-wise aggregation preprocessing for 3D MRI volumes
2) Read CV splits generated by fusion (expects 'test' indices per fold)
3) Load pretrained DINOv3 backbone
4) Load trained sklearn logistic regression model (.pkl from joblib)
5) Extract features -> logistic regression -> predictions on test set per fold
6) Compute the same metrics as protein baseline (Accuracy, Balanced Acc, AUC, Precision, Recall, F1, MCC)
7) Aggregate metrics across folds and save JSON

Key differences from BrainIAC baseline:
- Uses DINOv3's slice-wise aggregation for 3D->2D feature extraction
- Uses sklearn LogisticRegression instead of PyTorch linear probe
- Requires joblib-saved .pkl model checkpoint
"""

import argparse
import json
from pathlib import Path
from typing import List, Tuple
import sys

import numpy as np
import pandas as pd

import torch
import torch.nn as nn

from sklearn.metrics import (
    accuracy_score,
    balanced_accuracy_score,
    confusion_matrix,
    precision_recall_fscore_support,
    roc_auc_score,
    matthews_corrcoef,
)

# Add DINOv3 to path
_dinov3_root = Path(__file__).resolve().parents[2] / 'mri' / 'dinov3'
_dinov3_root_str = str(_dinov3_root)
if _dinov3_root_str not in sys.path:
    sys.path.insert(0, _dinov3_root_str)

# Import DINOv3 modules
from dinov3.data.transforms import make_classification_eval_transform  # type: ignore
from dinov3.data.datasets.adni_3d_aggregation import extract_features_with_slice_aggregation  # type: ignore


def normalize_path(path_str: str) -> Path:
    """Normalize to absolute path, stripping duplicate project prefix if present."""
    if isinstance(path_str, str) and path_str.startswith('multimodal-AD/'):
        cwd = Path.cwd()
        if cwd.name == 'multimodal-AD' or str(cwd).endswith('/multimodal-AD'):
            path_str = path_str.replace('multimodal-AD/', '', 1)
    return Path(path_str).expanduser().resolve()


class PathsLabelsDataset:
    """Minimal dataset adapter exposing the ADNI-like interface for slice aggregation.

    This dataset provides:
    - root: kept as empty string; absolute paths will be honored downstream
    - get_image_relpath(i): returns absolute file path string for index i
    - get_target(i): integer label for index i
    - get_targets(): numpy array of labels
    - transform: image transform for 2D slices
    """

    def __init__(self, image_paths: List[str], labels: np.ndarray, transform) -> None:
        self.root = ""
        self._paths = image_paths
        self._labels = labels.astype(int)
        self.transform = transform

    def __len__(self) -> int:
        return len(self._paths)

    def get_image_relpath(self, index: int) -> str:
        return self._paths[index]

    def get_target(self, index: int) -> int:
        return int(self._labels[index])

    def get_targets(self) -> np.ndarray:
        return self._labels.copy()

def load_dinov3_model(hub_repo_dir: Path, hub_model: str, pretrained_weights: Path, device: torch.device) -> nn.Module:
    """
    Load pretrained DINOv3 model using torch.hub.
    
    Args:
        hub_repo_dir: Path to DINOv3 repository
        hub_model: Model name (e.g., 'dinov3_vits16', 'dinov3_vitb16')
        pretrained_weights: Path to .pth weights file
        device: Device to load model on
    
    Returns:
        DINOv3 model in eval mode
    """
    print(f"Loading DINOv3 model: {hub_model}")
    print(f"  Hub repo: {hub_repo_dir}")
    print(f"  Weights: {pretrained_weights}")
    
    # Load model using torch.hub (local)
    model = torch.hub.load(
        str(hub_repo_dir),
        hub_model,
        source='local',
        pretrained=False
    )
    
    # Load pretrained weights
    state_dict = torch.load(str(pretrained_weights), map_location='cpu')
    model.load_state_dict(state_dict, strict=True)
    
    model.eval()
    model.to(device)
    
    print(f"  Model loaded successfully")
    return model


def load_sklearn_logreg(checkpoint_path: Path):
    """
    Load sklearn LogisticRegression model from joblib checkpoint.
    
    Args:
        checkpoint_path: Path to .pkl file saved by joblib.dump()
    
    Returns:
        Trained sklearn LogisticRegression estimator
    """
    import joblib
    
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")
    
    model = joblib.load(str(checkpoint_path))
    print(f"Loaded sklearn LogisticRegression from {checkpoint_path}")
    return model


def _safe_auc_score(y_true: np.ndarray, y_prob: np.ndarray) -> float:
    """Return AUC with robust handling for degenerate cases."""
    unique_labels = np.unique(y_true)
    unique_preds = np.unique((y_prob >= 0.5).astype(int))
    if len(unique_labels) < 2:
        return float('nan')
    if len(unique_preds) < 2:
        return 0.5
    try:
        return float(roc_auc_score(y_true, y_prob))
    except ValueError:
        return float('nan')


def evaluate_fold(
    dinov3_model: nn.Module,
    logreg_model,
    device: torch.device,
    df: pd.DataFrame,
    test_indices: np.ndarray,
    mri_root: Path,
    image_size: int = 224,
    slice_axis: int = 0,
    stride: int = 2,
) -> dict:
    """
    Run inference for a single fold's test set and compute metrics.
    
    Args:
        dinov3_model: Pretrained DINOv3 backbone
        logreg_model: Trained sklearn LogisticRegression
        device: Device for DINOv3 inference
        df: Full dataframe with all samples
        test_indices: Indices of test samples for this fold
        mri_root: Root directory containing NIfTI images
        image_size: Image size for DINOv3 transforms
        slice_axis: Axis to slice along (0=sagittal, 1=coronal, 2=axial)
        stride: Slice stride for aggregation
    
    Returns:
        Dict with test metrics for this fold
    """
    # Get test subset
    df_test = df.iloc[test_indices].reset_index(drop=True)

    # Build image paths and labels directly from CSV columns
    if 'mri_path' not in df_test.columns or 'research_group' not in df_test.columns:
        raise KeyError("CSV must contain 'mri_path' and 'research_group' columns for DINOv3 baseline")

    image_paths = [str(normalize_path(p)) for p in df_test['mri_path'].tolist()]
    labels = (df_test['research_group'] == 'AD').astype(int).to_numpy()

    # Create transform and dataset adapter
    transform = make_classification_eval_transform(
        resize_size=image_size,
        crop_size=image_size
    )

    dataset = PathsLabelsDataset(image_paths=image_paths, labels=labels, transform=transform)
    print(f"  Created dataset from CSV: {len(dataset)} samples")
        
    # Extract features using slice-wise aggregation
    features, labels_tensor = extract_features_with_slice_aggregation(
        model=dinov3_model,
        dataset=dataset,
        batch_size=1,
        num_workers=0,
        device=str(device),
        slice_axis=slice_axis,
        stride=stride
    )

    # Convert to numpy
    features_np = features.cpu().numpy()  # [N, feature_dim]
    labels_np = labels_tensor.cpu().numpy()  # [N]

    print(f"  Extracted features: {features_np.shape}")

    # Get predictions from sklearn LogisticRegression
    probas = logreg_model.predict_proba(features_np)  # [N, 2]
    y_prob = probas[:, 1]  # Probability of AD (class 1)
    y_pred = logreg_model.predict(features_np)  # [N]
    y_true = labels_np.astype(int)

    # Compute metrics
    test_acc = float(accuracy_score(y_true, y_pred))
    test_balanced_acc = float(balanced_accuracy_score(y_true, y_pred))
    precision, recall, f1, _ = precision_recall_fscore_support(
        y_true, y_pred, average='binary', zero_division=0
    )
    test_auc = _safe_auc_score(y_true, y_prob)
    test_cm = confusion_matrix(y_true, y_pred, labels=[0, 1])
    test_mcc = float(matthews_corrcoef(y_true, y_pred))

    return {
        'test_acc': test_acc,
        'test_balanced_acc': test_balanced_acc,
        'test_auc': test_auc,
        'test_precision': float(precision),
        'test_recall': float(recall),
        'test_f1': float(f1),
        'test_mcc': test_mcc,
        'test_cm': test_cm.tolist(),
        'n_test': int(len(y_true)),
    }


def print_fold_results(results: dict, fold_idx: int) -> None:
    """Print fold results in a formatted way."""
    print(f"\nFold {fold_idx} Test Results:")
    print(f"  Accuracy: {results['test_acc']:.4f}")
    print(f"  Balanced Accuracy: {results['test_balanced_acc']:.4f}")
    if np.isnan(results['test_auc']):
        print("  AUC: undefined")
    else:
        print(f"  AUC: {results['test_auc']:.4f}")
    print(f"  Precision: {results['test_precision']:.4f}")
    print(f"  Recall: {results['test_recall']:.4f}")
    print(f"  F1: {results['test_f1']:.4f}")
    print(f"  MCC: {results['test_mcc']:.4f}")
    cm = np.array(results['test_cm'])
    print("  Confusion Matrix:")
    print(f"    TN={cm[0,0]}, FP={cm[0,1]}")
    print(f"    FN={cm[1,0]}, TP={cm[1,1]}")


def aggregate_results(fold_results: List[dict]) -> Tuple[dict, np.ndarray]:
    """Aggregate results across folds."""
    metrics = ['test_acc', 'test_balanced_acc', 'test_auc', 'test_precision', 'test_recall', 'test_f1', 'test_mcc']
    aggregated = {}

    print("\n" + "="*60)
    print("CROSS-VALIDATION RESULTS SUMMARY (DINOv3 sMRI-ONLY BASELINE)")
    print("="*60)

    for metric in metrics:
        values = [fr[metric] for fr in fold_results]
        if metric == 'test_auc' and any(np.isnan(v) for v in values):
            aggregated[metric] = {
                'mean': float('nan'),
                'std': float('nan'),
                'values': values,
            }
            name = metric.replace('test_', '').replace('_', ' ').upper()
            print(f"{name}: undefined (some folds had undefined AUC)")
        else:
            valid = [v for v in values if not (isinstance(v, float) and np.isnan(v))]
            if valid:
                aggregated[metric] = {
                    'mean': float(np.mean(valid)),
                    'std': float(np.std(valid)),
                    'values': values,
                }
                name = metric.replace('test_', '').replace('_', ' ').upper()
                print(f"{name}: {aggregated[metric]['mean']:.4f} ± {aggregated[metric]['std']:.4f}")
            else:
                aggregated[metric] = {
                    'mean': float('nan'),
                    'std': float('nan'),
                    'values': values,
                }
                name = metric.replace('test_', '').replace('_', ' ').upper()
                print(f"{name}: undefined (all folds had undefined values)")

    total_cm = np.sum([np.array(fr['test_cm']) for fr in fold_results], axis=0)
    print("\nAggregated Confusion Matrix:")
    print(f"  TN={total_cm[0,0]}, FP={total_cm[0,1]}")
    print(f"  FN={total_cm[1,0]}, TP={total_cm[1,1]}")

    return aggregated, total_cm


def main():
    parser = argparse.ArgumentParser(
        description="Evaluate DINOv3 linear-probe sMRI model on fusion CV splits (inference only)"
    )
    parser.add_argument('--data-csv', type=str, required=True,
                        help='CSV containing paired dataset with columns: pat_id, label, mri_path, research_group')
    parser.add_argument('--cv-splits-json', type=str, required=True,
                        help='cv_splits.json produced by fusion run (expects list of {test: [...]})')
    parser.add_argument('--checkpoint-path', type=str, required=True,
                        help='Path to sklearn LogisticRegression checkpoint (.pkl from joblib)')
    parser.add_argument('--dinov3-hub-dir', type=str, required=True,
                        help='Path to DINOv3 repository directory')
    parser.add_argument('--dinov3-model', type=str, default='dinov3_vits16',
                        choices=['dinov3_vits16', 'dinov3_vitb16', 'dinov3_vitl16'],
                        help='DINOv3 model variant')
    parser.add_argument('--pretrained-weights', type=str, required=True,
                        help='Path to DINOv3 pretrained weights (.pth)')
    parser.add_argument('--mri-root', type=str, required=True,
                        help='Root directory containing NIfTI images (pat_id.nii.gz)')
    parser.add_argument('--save-dir', type=str, default=None,
                        help='Directory to save results JSON')
    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu',
                        choices=['cpu', 'cuda'])
    parser.add_argument('--image-size', type=int, default=224,
                        help='Image size for DINOv3 transforms')
    parser.add_argument('--slice-axis', type=int, default=0,
                        help='Axis to slice along (0=sagittal, 1=coronal, 2=axial)')
    parser.add_argument('--stride', type=int, default=2,
                        help='Slice stride for aggregation')
    args = parser.parse_args()

    # Normalize paths
    data_csv = normalize_path(args.data_csv)
    cv_splits_json = normalize_path(args.cv_splits_json)
    checkpoint_path = normalize_path(args.checkpoint_path)
    dinov3_hub_dir = normalize_path(args.dinov3_hub_dir)
    pretrained_weights = normalize_path(args.pretrained_weights)
    mri_root = normalize_path(args.mri_root)
    save_dir = normalize_path(args.save_dir) if args.save_dir else None

    device = torch.device(args.device)

    print("="*60)
    print("DINOv3 sMRI-ONLY BASELINE EVALUATION")
    print("="*60)
    print(f"Data CSV: {data_csv}")
    print(f"CV Splits: {cv_splits_json}")
    print(f"Checkpoint: {checkpoint_path}")
    print(f"DINOv3 Hub: {dinov3_hub_dir}")
    print(f"DINOv3 Model: {args.dinov3_model}")
    print(f"Pretrained Weights: {pretrained_weights}")
    print(f"MRI Root: {mri_root}")
    print(f"Device: {device}")
    print(f"Image Size: {args.image_size}")
    print(f"Slice Axis: {args.slice_axis}, Stride: {args.stride}")
    print()

    # Load data and splits
    df = pd.read_csv(str(data_csv))
    with open(str(cv_splits_json), 'r') as f:
        cv_splits = json.load(f)

    print(f"Loaded {len(df)} samples from CSV")
    print(f"Loaded {len(cv_splits)} CV folds")
    print()

    # Load DINOv3 model (frozen, inference only)
    dinov3_model = load_dinov3_model(
        hub_repo_dir=dinov3_hub_dir,
        hub_model=args.dinov3_model,
        pretrained_weights=pretrained_weights,
        device=device
    )

    # Load sklearn LogisticRegression
    logreg_model = load_sklearn_logreg(checkpoint_path)
    print()

    fold_results = []
    for fold_idx, split in enumerate(cv_splits, start=1):
        # Expect protein/fusion-style splits with 'test' indices
        if 'test' not in split:
            raise KeyError("CV split must contain 'test' key with indices to evaluate")
        test_idx = np.asarray(split['test'], dtype=int)

        print("-"*60)
        print(f"FOLD {fold_idx}/{len(cv_splits)}  |  Test size: {len(test_idx)}")

        res = evaluate_fold(
            dinov3_model=dinov3_model,
            logreg_model=logreg_model,
            device=device,
            df=df,
            test_indices=test_idx,
            mri_root=mri_root,
            image_size=args.image_size,
            slice_axis=args.slice_axis,
            stride=args.stride,
        )
        res['fold'] = fold_idx
        fold_results.append(res)
        print_fold_results(res, fold_idx)

    aggregated, total_cm = aggregate_results(fold_results)

    if save_dir is not None:
        save_dir.mkdir(parents=True, exist_ok=True)
        output = {
            'fold_results': fold_results,
            'aggregated_metrics': {
                k: {
                    'mean': None if isinstance(v['mean'], float) and np.isnan(v['mean']) else v['mean'],
                    'std': None if isinstance(v['std'], float) and np.isnan(v['std']) else v['std'],
                    'values': [None if isinstance(x, float) and np.isnan(x) else x for x in v['values']],
                } for k, v in aggregated.items()
            },
            'aggregated_cm': total_cm.tolist(),
        }
        with open(save_dir / 'dinov3_linear_probe_baseline_results.json', 'w') as f:
            json.dump(output, f, indent=2)
        print(f"\n✅ Results saved to: {save_dir / 'dinov3_linear_probe_baseline_results.json'}")


if __name__ == '__main__':
    main()

